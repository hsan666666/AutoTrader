{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsan666666/AutoTrader/blob/main/Another_copy_of_01_working_with_raw_lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Foundation Language Models\n",
        "\n",
        "Such models are not trained to complete chat turns nor are they explicitly trained to respond to specific instructions such as \"Summarize the following text ...\". Nonetheless, when prompted properly these models can achieve an impressive level of performance in doing such tasks.\n",
        "\n",
        "These models are trained on vast amounts of text data usually crawled from the Internet, including books, code, articles, news, etc. They are trained to complete the input text with the most probable words. Keep that in mind when trying to prompt such models.\n",
        "\n",
        "One important learning from this exercise: do not try to make these models do what they have not seen in the pre-training data, and your life will be easier. This maxima also can be applied to the chat LMs models.\n"
      ],
      "metadata": {
        "id": "gm7sEpKEGVr_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this exercise, we will be using open-source models that we can get from huggingface. If you have time, do try to use other models as well.\n"
      ],
      "metadata": {
        "id": "0xbcx79UGhRP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9krD-ESxMxo"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "_new_max_tokens = 32 if not torch.cuda.is_available() else 128\n",
        "\n",
        "# If you are using Apple M1, M2, M3 on your local machine\n",
        "# if not torch.cuda.is_available() and torch.backends.mps.is_available():\n",
        "#   if torch.backends.mps.is_built():\n",
        "#       device = \"mpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model is Qwen1.5. The model contains 0.5B parameters, you might be able to use this model both on the CPU (slow) and GPU (much faster). Do switch your runtime to T4 GPU to accelerate completion (Runtime -> Change Runtime Type). Note that Google Colab has limits on GPU usage, the resources are not guaranteed."
      ],
      "metadata": {
        "id": "Nyv8Fyi-ERJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Qwen/Qwen1.5-0.5B\"\n",
        "# if you want a higher degree of challenge, use the following models:\n",
        "# model_name = \"gpt2\"\n",
        "# model_name = \"gpt2-medium\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\").to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def complete(primer, max_new_tokens=_new_max_tokens):\n",
        "  inputs = tokenizer(primer, return_tensors=\"pt\").to(device)\n",
        "\n",
        "  outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "  generated_ids = outputs[0][len(inputs.input_ids[0]):]\n",
        "\n",
        "  return primer, tokenizer.decode(generated_ids, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "3rlgERp5xWOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Completion is the standard task for LMs, we can use it to write a story from a primer."
      ],
      "metadata": {
        "id": "fN6JA0aQHdwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Once upon a time, in a quiet village, a young girl discovered a hidden world in her backyard. She was exploring the dense bushes when she stumbled upon a\"\n",
        "\n",
        "primer, completion = complete(prompt)\n",
        "\n",
        "print(\"START >>\\n\\n\", primer, sep=\"\")\n",
        "print()\n",
        "print(\"COMPLETION >>\\n\\n\", completion, sep=\"\")\n"
      ],
      "metadata": {
        "id": "iD-T0p5_zHa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although we face the completion task all the time (GMAIL would suggest how to finish the sentence, a keyboard app on your phone would recommend the next word, etc.), in the business settings we are interested in solving other problems, like summarization.\n",
        "\n",
        "In the following example, try to make the LM to summarize this passage for you."
      ],
      "metadata": {
        "id": "KF9SmDs5IGDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_summarize = \\\n",
        "\"\"\"Artificial intelligence (AI) is a rapidly growing field with applications in various industries.\n",
        "From healthcare to finance, AI is transforming how we approach complex problems. In healthcare, AI\n",
        "is being used to develop advanced diagnostic tools and personalized treatment plans. In finance,\n",
        "AI is enhancing fraud detection and algorithmic trading. Despite these advancements,\n",
        "there are ethical concerns surrounding AI, including privacy and bias issues.\"\"\"\n",
        "\n",
        "prompt = \\\n",
        "\"\"\"{text}\n",
        "\n",
        "In summary,\n",
        "\"\"\"\n",
        "\n",
        "primer, completion = complete(prompt.format(text=text_to_summarize))\n",
        "\n",
        "print(\"START >>\\n\\n\", primer, sep=\"\")\n",
        "print()\n",
        "print(\"COMPLETION >>\\n\\n\", completion, sep=\"\")"
      ],
      "metadata": {
        "id": "8oUzGBogzRMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the most prominent use cases for LMs is code-writing. Could you make the LM write a code for you that would check:\n",
        "\n",
        "1. If the number is prime: https://en.wikipedia.org/wiki/Prime_number\n",
        "2. That finds the greatest common divisor of two integers: https://en.wikipedia.org/wiki/Greatest_common_divisor"
      ],
      "metadata": {
        "id": "6IOayVYuIXh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \\\n",
        "\"\"\"\n",
        "<put your prompt here>\n",
        "\"\"\"\n",
        "\n",
        "primer, completion = complete(prompt)\n",
        "\n",
        "print(\"START >>\\n\\n\", primer, sep=\"\")\n",
        "print()\n",
        "print(\"COMPLETION >>\\n\\n\", completion, sep=\"\")"
      ],
      "metadata": {
        "id": "6aSTMw2g5AKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Showcase the poetic skills of the LM. Write a haiku about nature. (https://en.wikipedia.org/wiki/Haiku)"
      ],
      "metadata": {
        "id": "3fwnwPGlJZ4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \\\n",
        "\"\"\"\n",
        "<put your prompt here>\n",
        "\"\"\"\n",
        "\n",
        "primer, completion = complete(prompt)\n",
        "\n",
        "print(\"START >>\\n\\n\", primer, sep=\"\")\n",
        "print()\n",
        "print(\"COMPLETION >>\\n\\n\", completion, sep=\"\")"
      ],
      "metadata": {
        "id": "pfS0P8X056Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the LM answer a question based on the passage."
      ],
      "metadata": {
        "id": "Sl5RGz5cJncJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference_text = \\\n",
        "\"\"\"The Amazon rainforest is the largest tropical rainforest in the world, covering over 5.5 million square kilometers.\n",
        "It is home to an estimated 390 billion individual trees and is often referred to as the 'lungs of the Earth'\n",
        "due to its role in producing oxygen and absorbing carbon dioxide. The rainforest is also home to millions of\n",
        "species of plants and animals, many of which are not found anywhere else on Earth.\"\"\"\n",
        "\n",
        "question = \"Why is the Amazon rainforest referred to as the 'lungs of the Earth'?\"\n",
        "\n",
        "prompt = \\\n",
        "\"\"\"{text}\"\"\"\n",
        "\n",
        "primer, completion = complete(prompt.format(text=reference_text))\n",
        "\n",
        "print(\"START >>\\n\\n\", primer, sep=\"\")\n",
        "print()\n",
        "print(\"COMPLETION >>\\n\\n\", completion, sep=\"\")"
      ],
      "metadata": {
        "id": "gn99xOuH8NfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the LM come up with a product name!"
      ],
      "metadata": {
        "id": "dsdoLAgGJu2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "product_description = \\\n",
        "\"\"\"The headphones feature cutting-edge technology to deliver premium sound quality and the best noise-cancelling\n",
        "performance on the market. Real-time audio processors and high-performance mics power the specially designed\n",
        "driver unit, for wide frequency reproduction, deep bass and clear vocals. They are designed to immerse you in\n",
        "a sound so good, it's feels like youâ€™re in the studio with your favourite artists. The\n",
        "headphones raise the bar for distraction-free listening and clarity.\"\"\"\n",
        "\n",
        "prompt = \\\n",
        "\"\"\"{text}\"\"\"\n",
        "\n",
        "primer, completion = complete(prompt.format(text=product_description))\n",
        "\n",
        "print(\"START >>\\n\\n\", primer, sep=\"\")\n",
        "print()\n",
        "print(\"COMPLETION >>\\n\\n\", completion, sep=\"\")"
      ],
      "metadata": {
        "id": "yDPozMkO8kTw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}